# -*- coding: utf-8 -*-
"""System_Recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/102QeMGol1ttJjezWeZIwiNgeJ6DewRJJ

#Import Library
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import warnings
import os, shutil
os.listdir()

from zipfile import ZipFile
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""Mengimport beberapa library yang dibutuhkan dalam proyek."""

warnings.filterwarnings("ignore")

"""Menonaktifkan semua peringatan

#Load Dataset

Dataset ini diunduh dari Kaggle. Untuk menyambungkan Google Colaboratory dengan Kaggle digunakan perantara Gdrive. File kaggle.json disimpan dalam folder Gdrive yang nantinya akan dipanggil (untuk mengamankan keyword dari file .json).
"""

from google.colab import drive
drive.mount('/content/drive')

# Buat direktori .kaggle
os.makedirs("/root/.kaggle", exist_ok=True)

# Copy file dari Google Drive
shutil.copy("/content/drive/MyDrive/kaggle/kaggle.json", "/root/.kaggle/kaggle.json")

# Ubah permission-nya
os.chmod("/root/.kaggle/kaggle.json", 600)

!kaggle datasets download -d nicoletacilibiu/movies-and-ratings-for-recommendation-system

!unzip movies-and-ratings-for-recommendation-system.zip -d movies-and-ratings-for-recommendation-system

## Load the data
movies = pd.read_csv('movies-and-ratings-for-recommendation-system/movies.csv')
ratings = pd.read_csv('movies-and-ratings-for-recommendation-system/ratings.csv')

"""movies : merupakan daftar movie yang tersedia

ratings : merupakan daftar penilaian yang diberikan pengguna terhadap movie.

#Data Understanding

##Explanatory Data Analysis
"""

print('Jumlah data movie: ', len(movies.movieId.unique()))
print('Jumlah data rating: ', len(ratings.movieId.unique()))

"""###Movie"""

movies.head()

movies.info()

"""movies.csv memiliki 9742 entri. Terdapat tiga variabel di sini, yaitu movieId, title dan genres. movieId merupakan ID movie, title merupakan judul movie sedangkan genres merupakan jenis genre yang ada di movie."""

movies.describe()

print('Banyak movie: ', len(movies.movieId.unique()))
print('Judul movie yang dimiliki: ', movies.title.unique())

"""Terdapat 9742 data movie yang unik.

###Rating
"""

ratings.head()

ratings.info()

"""ratings.csv memiliki 100836 entri. Terdapat empat variabel di sini, yaitu userId, movieId, rating dan timestamp."""

ratings.describe()

"""Dari output di atas, diketahui bahwa nilai maksimum rating adalah 5 dan nilai minimumnya adalah 0. Artinya, skala rating berkisar antara 0 hingga 5."""

plt.figure(figsize=(10, 6))
sns.histplot(data=ratings, x='rating', bins=10, color='skyblue')

plt.title('Distribusi Rating Film')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.grid(True)
plt.tight_layout()
plt.show()

"""Dari plot di atas dapat dijelaskan bahwa rating terbanyak ada dikisaran 4. Rating tersebut menunjukkan bahwa data movie yang tersedia merupakan movie yang disukai oleh user.

#Data Prepraration

###Menggabungkan seluruh data
"""

# Menggabungkan dataframe rating dengan movies berdasarkan nilai movieId
movie = pd.merge(ratings, movies , on='movieId', how='left')

movie.head()

movie.info()

movie.describe()

"""Dari informasi di atas dapat dijelaskan bahwa minimal rating yang ada adalah 0.5 dan maksimal rating yang ada adalah 5.

##Cek Missing Value
"""

movie.isnull().sum()

"""Tidak ada missing value (NaN) pada fitur movie."""

movie.groupby('movieId').sum()

"""Data dikelompokkan berdasarkan movieId"""

# Mengurutkan movie berdasarkan movieId kemudian memasukkannya ke dalam variabel fix_movie
fix_movie = movie.sort_values('movieId', ascending=True)
fix_movie

"""Data diurutkan secara ascending berdasarkan movieId"""

# Mengecek berapa jumlah fix_movie
len(fix_movie.movieId.unique())

"""Jumlah data uniqe yang dimiliki oleh movieId adalah 9742"""

# Membuat variabel preparation yang berisi dataframe fix_movie kemudian mengurutkan berdasarkan movieId
preparation = fix_movie
preparation.sort_values('movieId')

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('movieId')
preparation

"""Setelah membuat data baru yaitu preparation, membuang data duplikat pada semua variabel preparation"""

# Mengonversi data series ‘movieId’ menjadi dalam bentuk list
movie_id = preparation['movieId'].tolist()

# Mengonversi data series ‘Name’ menjadi dalam bentuk list
movie_name = preparation['title'].tolist()

# Mengonversi data series ‘Genre’ menjadi dalam bentuk list
movie_genre = preparation['genres'].tolist()

"""Variabel movieId, title dan genres dikonversi menjadi dalam bentuk list"""

print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

# Membuat dictionary untuk data ‘movie_id’, ‘movie_name’, dan ‘genre’
movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new

"""Dictionary yang telah dibuat yaitu movie_new digunakan untuk pemodelan

#Model Development

##Content Based Filtering
"""

data = movie_new
data.sample(5)

"""Menyimpan salinan atau referensi dari DataFrame movie_new ke dalam variabel data

###TF-IDF Vectorizer
"""

# Inisialisasi TfidfVectorizer
tfidf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tfidf.fit(data['genre'])

"""Mempersiapkan data teks dalam kolom genre agar bisa digunakan dalam Content-Based Filtering dengan teknik TF-IDF (Term Frequency - Inverse Document Frequency)"""

# Mapping array dari fitur index integer ke fitur nama
tfidf.get_feature_names_out()

"""Terdapat 20 jenis genre yang ada"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tfidf.fit_transform(data['genre'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Perhatikanlah, matriks yang kita miliki berukuran (9724, 22). Nilai 9724 merupakan ukuran data dan 24 merupakan matrik kategori genre"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis genre
# Baris diisi dengan nama movie

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.movie_name
).sample(24, axis=1).sample(10, axis=0)

"""###Cosine Similarity"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Menghitung kemiripan antar film berdasarkan genre-nya menggunakan representasi vektor TF-IDF"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama movie
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['movie_name'], columns=data['movie_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap movie
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Melihat nilai similarity antar 10 film terhadap 5 film lainnya secara acak—berguna untuk mengecek distribusi nilai kemiripan

###Mendapatkan Rekomendasi
"""

def movie_recommendations(nama_movie, similarity_data=cosine_sim_df, items=data[['movie_name', 'genre']], k=5):
    """
    Rekomendasi Movie berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_movie : tipe data string (str)
                Nama movie (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan resto sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop movie_resto agar movie resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_movie, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Membangun sistem rekomendasi film berbasis konten (Content-Based Filtering) dengan menggunakan kemiripan antar film berdasarkan genre-nya, yang dihitung sebelumnya dengan cosine similarity."""

data[data.movie_name.eq('If I Stay (2014)')]

"""Mencari data film dengan judul "If I Stay (2014)" di DataFrame data"""

# Mendapatkan rekomendasi movie yang mirip dengan If I Stay (2014)
movie_recommendations('If I Stay (2014)')

"""Hasil dari sistem rekomendasi berupa DataFrame berisi daftar film yang mirip dengan "If I Stay (2014)", berdasarkan genre-nya, menggunakan pendekatan Content-Based Filtering (cosine similarity + TF-IDF)

##Collaborative Filtering
"""

# Membaca dataset
df = ratings
df

"""Menampilkan isi dari df, sehingga bisa melihat isi tabel tersebut langsung

###Data Preparation
"""

# Mengubah userId menjadi list tanpa nilai yang sama
user_ids = df['userId'].unique().tolist()
print('list userId: ', user_ids)

# Melakukan encoding userId
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

"""Kode di atas berfungsi untuk mengubah dan memetakan userId dalam dataset menjadi angka untuk memudahkan proses dalam model rekomendasi."""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

"""Kode di atas bertujuan untuk melakukan encoding pada kolom movieId dalam dataset."""

# Mapping userId ke dataframe genre
df['genre'] = df['userId'].map(user_to_user_encoded)

# Mapping movieId ke dataframe movie
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

"""Kode di atas bertujuan untuk memetakan (mapping) nilai userId dan movieId ke dalam encoding numerik di DataFrame df."""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah movie
num_movie = len(movie_encoded_to_movie)
print(num_movie)

# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""###Splitting Data"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df[['genre', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

"""Kode di atas bertujuan untuk menyiapkan data untuk proses pelatihan model dengan dua variabel utama: x untuk fitur dan y untuk target/label."""

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Data dibagi menjadi 80% data training dan 20% data validasi/testing

###Training Data
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movie
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movie bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Kode yang diberikan mendefinisikan sebuah kelas model jaringan saraf untuk sistem rekomendasi yang disebut RecommenderNet, yang menggunakan embedding untuk pengguna dan film."""

model = RecommenderNet(num_users, num_movie, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation."""

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 128,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""###Visualisasi Metrics"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Dari plot di atas dapat dilihat bahwa hasil rmse antara train dan test tidak begitu jauh."""

# Ambil nilai RMSE terakhir
rmse_train = history.history['root_mean_squared_error'][-1]
rmse_val = history.history['val_root_mean_squared_error'][-1]

# Hitung MSE
mse_train = rmse_train ** 2
mse_val = rmse_val ** 2

# Tampilkan nilai
print(f"RMSE Train (epoch terakhir): {rmse_train:.4f}")
print(f"RMSE Val (epoch terakhir): {rmse_val:.4f}")

"""###Mendapatkan Rekomendasi Movie"""

movie_df = movie_new
df = pd.read_csv('movies-and-ratings-for-recommendation-system/ratings.csv')

# Mengambil sample user
user_id = df.userId.sample(1).iloc[0]
movie_on_by_user = df[df.userId == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
movie_off = movie_df[~movie_df['id'].isin(movie_on_by_user.movieId.values)]['id']
movie_off = list(
    set(movie_off)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_off = [[movie_to_movie_encoded.get(x)] for x in movie_off]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_off), movie_off)
)

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_off[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Movie with high ratings from user')
print('----' * 8)

top_movie_user = (
    movie_on_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_name, ':', row.genre)

print('----' * 8)
print('Top 10 Movie recommendation')
print('----' * 8)

recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.movie_name, ':', row.genre)

"""Informasi di atas merupakan hasil rekomendasi dari collaborative filtering. Terdapat 10 top movie yang direkomendasikan, sesuai dengan movie dengan rating tertinggi dari user."""